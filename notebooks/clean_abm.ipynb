{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available parquet files (12):  ['flight_data_2024_9.parquet', 'flight_data_2025_3.parquet', 'flight_data_2024_8.parquet', 'flight_data_2025_2.parquet', 'flight_data_2025_1.parquet', 'flight_data_2025_4.parquet', 'flight_data_2024_7.parquet', 'flight_data_2024_12.parquet', 'flight_data_2025_5.parquet', 'flight_data_2024_11.parquet', 'flight_data_2025_6.parquet', 'flight_data_2024_10.parquet']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import os\n",
    "\n",
    "#############################################################################################################\n",
    "### FUNCTIONS\n",
    "#############################################################################################################\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Load parquet files (should have 12 months worth of data)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def load_parquet_files(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "    print(\"Available parquet files (\" + str(len(files)) + \"): \", files)\n",
    "    df = pd.concat([pd.read_parquet(os.path.join(directory, f)) for f in files], ignore_index=True)\n",
    "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "    return df\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### General data cleaning (remove duplicates, fill NAs, etc)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def clean_and_filter_columns(df, columns, delay_cols):\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df[[col for col in columns if col in df.columns]].drop_duplicates()\n",
    "    df[delay_cols] = df[delay_cols].fillna(0)\n",
    "    df[delay_cols] = df[delay_cols].astype(int)\n",
    "    return df\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Convert departure / arrival times from HHMM (ex. 1420 for 14:20 PM) to minutes after midnight (ex. 860)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def extract_minutes_after_midnight(df, colname, new_colname):\n",
    "    df[colname] = pd.to_numeric(df[colname], errors='coerce')  # convert to numeric, NaNs if invalid\n",
    "    hours = df[colname] // 100\n",
    "    minutes = df[colname] % 100\n",
    "    df[new_colname] = hours * 60 + minutes\n",
    "    return df\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Filter to only 50 US states & DC (excludes Canadian and other US territories)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def filter_valid_states(df, valid_states):\n",
    "    return df[df['originstate'].isin(valid_states) & df['deststate'].isin(valid_states)].copy()\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Filter to top 200 airports based on combined arrival and departures\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_top_airports(df, n=200):\n",
    "    origin = df['origin'].value_counts()\n",
    "    dest = df['dest'].value_counts()\n",
    "    combined = origin.add(dest, fill_value=0)\n",
    "    return combined.nlargest(n).index\n",
    "\n",
    "def filter_by_top_airports(df, top_airports):\n",
    "    return df[\n",
    "        df['origin'].isin(top_airports) & df['dest'].isin(top_airports)\n",
    "    ].copy()\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Create features based on proximity to holidays\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def add_holiday_features(df, max_window=14, sentinel=99):\n",
    "    # Step 1: Add a datetime column\n",
    "    date_cols = df[['year', 'month', 'dayofmonth']].copy()\n",
    "    date_cols.rename(columns={'dayofmonth': 'day'}, inplace=True)\n",
    "    df['flight_date'] = pd.to_datetime(date_cols)\n",
    "\n",
    "    # Step 2: Define relevant US holidays\n",
    "    years = df['year'].unique()\n",
    "    us_holidays = holidays.US(years=years)\n",
    "\n",
    "    major_holidays = {\n",
    "        \"New Year's Day\",\n",
    "        \"Memorial Day\",\n",
    "        \"Independence Day\",\n",
    "        \"Labor Day\",\n",
    "        \"Thanksgiving\",\n",
    "        \"Christmas Day\"\n",
    "    }\n",
    "\n",
    "    filtered_holidays = {date: name for date, name in us_holidays.items() if name in major_holidays}\n",
    "    holiday_dates = sorted(filtered_holidays.keys())\n",
    "\n",
    "    # Step 3: Calculate proximity to nearest holiday\n",
    "    def get_days_from_nearest_holiday(date):\n",
    "        closest_delta = None\n",
    "        for holiday in holiday_dates:\n",
    "            delta = (date.date() - holiday).days\n",
    "            if abs(delta) <= max_window:\n",
    "                if (closest_delta is None) or (abs(delta) < abs(closest_delta)):\n",
    "                    closest_delta = delta\n",
    "                    closest_holiday = holiday\n",
    "        return closest_delta\n",
    "\n",
    "    # Step 3: Calculate proximity to nearest holiday\n",
    "    def get_nearest_holiday(date):\n",
    "        closest_delta = None\n",
    "        closest_holiday = None\n",
    "        for holiday in holiday_dates:\n",
    "            delta = (date.date() - holiday).days\n",
    "            if abs(delta) <= max_window:\n",
    "                if (closest_delta is None) or (abs(delta) < abs(closest_delta)):\n",
    "                    closest_delta = delta\n",
    "                    closest_holiday = holiday\n",
    "        return closest_holiday\n",
    "\n",
    "\n",
    "    df['days_from_holiday_temp'] = df['flight_date'].apply(get_days_from_nearest_holiday)\n",
    "    df['if_near_holiday'] = df['days_from_holiday_temp'].notna().astype(int)\n",
    "    df['days_from_holiday'] = df['days_from_holiday_temp'].fillna(sentinel).astype(int)\n",
    "\n",
    "    df['holiday'] = df['flight_date'].apply(get_nearest_holiday)\n",
    "    df['holiday'] = df['holiday'].fillna(\"NA\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "### CALL MAIN\n",
    "#############################################################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cols = ['year', 'month', 'dayofmonth', 'dayofweek', 'origin', 'dest', 'reporting_airline', \n",
    "        'originstate', 'deststate', 'crsdeptime', 'crsarrtime','carrierdelay', 'weatherdelay', \n",
    "        'nasdelay', 'securitydelay', 'lateaircraftdelay', 'arrdelayminutes', 'cancelled', 'diverted']\n",
    "    delay_cols = ['carrierdelay', 'weatherdelay', 'nasdelay', 'securitydelay', \n",
    "        'lateaircraftdelay', 'arrdelayminutes']\n",
    "    state_list = ['AK','AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','HI','IA','ID','IL','IN',\n",
    "        'KS','KY','LA','MA','MD','ME','MI','MN','MO','MS','MT','NC','ND','NE','NH','NJ','NM','NV',\n",
    "        'NY','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VA','VT','WA','WI','WV','WY']\n",
    "\n",
    "    df_raw = load_parquet_files(\"../data/raw\")\n",
    "    df_clean = clean_and_filter_columns(df_raw, cols, delay_cols)\n",
    "    df_filtered = filter_valid_states(df_clean, state_list)\n",
    "    df_filtered = df_filtered.drop(columns=['originstate', 'deststate'])\n",
    "    df_filtered = extract_minutes_after_midnight(df_filtered, 'crsdeptime', 'deptime_mins')\n",
    "    df_filtered = extract_minutes_after_midnight(df_filtered, 'crsarrtime', 'arrtime_mins')\n",
    "    df_filtered = df_filtered.drop(columns=['crsdeptime', 'crsarrtime'])\n",
    "    df_filtered = add_holiday_features(df_filtered)\n",
    "    df_filtered = df_filtered.drop(columns=['year', 'flight_date', 'days_from_holiday_temp'])\n",
    "    df_filtered['if_delay'] = np.where(df_filtered['arrdelayminutes'] <= 15, '0', '1').astype(int) # delays defined as more than 15 minutes\n",
    "    df_filtered['if_cancelled'] = np.where(df_filtered['cancelled'] == 0, '0', '1').astype(int)\n",
    "    df_filtered['if_diverted'] = np.where(df_filtered['diverted'] == 0, '0', '1').astype(int)\n",
    "    df_filtered = df_filtered.drop(columns=['cancelled', 'diverted'])\n",
    "    top_airports = get_top_airports(df_filtered)\n",
    "    df_final = filter_by_top_airports(df_filtered, top_airports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "### SUMMARY STATISTICS DATASET\n",
    "#############################################################################################################\n",
    "\n",
    "summary_cols = ['origin', 'dest', 'reporting_airline', 'month', 'dayofweek', 'if_near_holiday']\n",
    "\n",
    "df_summary = df_final.copy().groupby(summary_cols).agg(\n",
    "    total_flights = ('if_delay', 'count'),\n",
    "    delayed_flights = ('if_delay', 'sum'),\n",
    "    cancelled_flights = ('if_cancelled', 'sum'),\n",
    "    diverted_flights = ('if_diverted', 'sum'),\n",
    "    total_delay_minutes = ('arrdelayminutes', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "df_summary.to_parquet('../data/processed/summary_dataset.parquet')\n",
    "\n",
    "#############################################################################################################\n",
    "### MACHINE LEARNING DATASET\n",
    "#############################################################################################################\n",
    "\n",
    "df_ml = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_sandbox_cols = ['origin', 'if_near_holiday']\n",
    "\n",
    "df_summary_sandbox = df_final.copy().groupby(summary_sandbox_cols).agg(\n",
    "    total_flights = ('if_delay', 'count'),\n",
    "    delayed_flights = ('if_delay', 'sum'),\n",
    "    cancelled_flights = ('if_cancelled', 'sum'),\n",
    "    diverted_flights = ('if_diverted', 'sum'),\n",
    "    total_delay_minutes = ('arrdelayminutes', 'sum'),\n",
    "    delay_minutes_90th = ('arrdelayminutes', lambda x: int(x.quantile(0.90))),\n",
    "    delay_minutes_95th = ('arrdelayminutes', lambda x: int(x.quantile(0.95))),\n",
    "    delay_minutes_99th = ('arrdelayminutes', lambda x: int(x.quantile(0.99))),\n",
    ").reset_index()\n",
    "\n",
    "df_summary_sandbox['avg_delay'] = df_summary_sandbox['total_delay_minutes'] / df_summary_sandbox['delayed_flights']\n",
    "df_summary_sandbox['delay_percent'] = (100 * df_summary_sandbox['delayed_flights'] / df_summary_sandbox['total_flights']).round(1)\n",
    "df_summary_sandbox['delay_percent_str'] = (100 * df_summary_sandbox['delayed_flights'] / df_summary_sandbox['total_flights']).round(1).astype(str) + '%'\n",
    "df_summary_sandbox['cancelled_percent'] = (100 * df_summary_sandbox['cancelled_flights'] / df_summary_sandbox['total_flights']).round(1).astype(str) + '%'\n",
    "df_summary_sandbox['diverted_percent'] = (100 * df_summary_sandbox['diverted_flights'] / df_summary_sandbox['total_flights']).round(1).astype(str) + '%'\n",
    "\n",
    "df_summary_sandbox.sort_values(by='delay_percent').tail(50)\n",
    "\n",
    "#df_summary_sandbox[df_summary_sandbox['holiday'] == \"NA\"].sort_values(by='delay_percent')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b42aa77ed5f5b42884b87ca53fed36318530525cc8445095b22cbadc9646f115"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
