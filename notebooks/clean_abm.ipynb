{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import os\n",
    "\n",
    "#############################################################################################################\n",
    "### FUNCTIONS\n",
    "#############################################################################################################\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Load parquet files (should have 12 months worth of data)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def load_parquet_files(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "    print(\"Available parquet files (\" + str(len(files)) + \"): \", files)\n",
    "    df = pd.concat([pd.read_parquet(os.path.join(directory, f)) for f in files], ignore_index=True)\n",
    "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "    return df\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### General data cleaning (remove duplicates, fill NAs, etc)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def clean_and_filter_columns(df, columns, delay_cols):\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df[[col for col in columns if col in df.columns]].drop_duplicates()\n",
    "    df[delay_cols] = df[delay_cols].fillna(0)\n",
    "    df[delay_cols] = df[delay_cols].astype(int)\n",
    "    return df\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Extract hour (0–23) directly from HHMM-formatted time (e.g., 1420 → 14)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def extract_hour_from_hhmm(df, colname, new_colname):\n",
    "    df[colname] = pd.to_numeric(df[colname], errors='coerce')  # ensure numeric\n",
    "    df[new_colname] = (df[colname] // 100).astype('Int64')     # supports NA\n",
    "    return df\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Filter to only 50 US states & DC (excludes Canadian and other US territories)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def filter_valid_states(df, valid_states):\n",
    "    return df[df['originstate'].isin(valid_states) & df['deststate'].isin(valid_states)].copy()\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Filter to top 200 airports based on combined arrival and departures\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_top_airports(df, n=200):\n",
    "    origin = df['origin'].value_counts()\n",
    "    dest = df['dest'].value_counts()\n",
    "    combined = origin.add(dest, fill_value=0)\n",
    "    return combined.nlargest(n).index\n",
    "\n",
    "def filter_by_top_airports(df, top_airports):\n",
    "    return df[\n",
    "        df['origin'].isin(top_airports) & df['dest'].isin(top_airports)\n",
    "    ].copy()\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Create categorical feature for proximity to major US holidays\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def add_holiday_features(df):\n",
    "\n",
    "    # Step 1: Convert to datetime\n",
    "    df['flight_date'] = pd.to_datetime(df[['year', 'month', 'dayofmonth']].rename(columns={'dayofmonth': 'day'}))\n",
    "\n",
    "    # Step 2: Major holidays and codes\n",
    "    us_holidays = holidays.US(years=df['year'].unique())\n",
    "\n",
    "    major_holidays = {\n",
    "        \"New Year's Day\": \"A\",\n",
    "        \"Memorial Day\": \"B\",\n",
    "        \"Independence Day\": \"C\",\n",
    "        \"Labor Day\": \"D\",\n",
    "        \"Thanksgiving Day\": \"E\",\n",
    "        \"Christmas Day\": \"F\"\n",
    "    }\n",
    "\n",
    "    # Filter to relevant holiday dates and codes\n",
    "    holiday_info = [\n",
    "        (pd.Timestamp(date), code)\n",
    "        for date, name in us_holidays.items()\n",
    "        if name in major_holidays\n",
    "        for code in [major_holidays[name]]\n",
    "    ]\n",
    "\n",
    "    if not holiday_info:\n",
    "        df['holiday_proximity_bucket'] = 5\n",
    "        df['holiday_code'] = 'NA'\n",
    "        return df\n",
    "\n",
    "    # Step 3: Build holiday date array\n",
    "    holiday_dates = np.array([d[0] for d in holiday_info], dtype='datetime64[D]')\n",
    "    holiday_codes = np.array([d[1] for d in holiday_info])\n",
    "\n",
    "    # Step 4: Calculate days difference (vectorized)\n",
    "    flight_dates = df['flight_date'].values.astype('datetime64[D]')\n",
    "    date_diffs = flight_dates[:, None] - holiday_dates[None, :]  # shape (N_flights, N_holidays)\n",
    "    delta_days = np.abs(date_diffs.astype('timedelta64[D]').astype(int))  # in days\n",
    "\n",
    "    # Step 5: Find nearest holiday within 7 days\n",
    "    min_diff = np.min(delta_days, axis=1)\n",
    "    min_idx = np.argmin(delta_days, axis=1)\n",
    "\n",
    "    # Step 6: Assign bucket based on delta\n",
    "    bucket = np.full(len(df), 5)  # Default: 5 = not near holiday\n",
    "    bucket[min_diff == 0] = 1\n",
    "    bucket[(min_diff == 1)] = 2\n",
    "    bucket[(min_diff >= 2) & (min_diff <= 3)] = 3\n",
    "    bucket[(min_diff >= 4) & (min_diff <= 7)] = 4\n",
    "\n",
    "    # Step 7: Assign holiday code (or NA if not within range)\n",
    "    code = np.array(['NA'] * len(df), dtype=object)\n",
    "    within_range = min_diff <= 7\n",
    "    code[within_range] = holiday_codes[min_idx[within_range]]\n",
    "\n",
    "    # Step 8: Assign to dataframe\n",
    "    df['holiday_proximity_bucket'] = bucket\n",
    "    df['holiday_code'] = code\n",
    "\n",
    "    return df\n",
    "\n",
    "#############################################################################################################\n",
    "### CALL MAIN\n",
    "#############################################################################################################\n",
    "\n",
    "# delays defined as more than 15 minutes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cols = ['year', 'month', 'dayofmonth', 'dayofweek', 'origin', 'dest', 'reporting_airline', \n",
    "        'originstate', 'deststate', 'crsdeptime', 'crsarrtime','carrierdelay', 'weatherdelay', \n",
    "        'nasdelay', 'securitydelay', 'lateaircraftdelay', 'arrdelayminutes', 'cancelled', 'diverted']\n",
    "    delay_cols = ['carrierdelay', 'weatherdelay', 'nasdelay', 'securitydelay', \n",
    "        'lateaircraftdelay', 'arrdelayminutes']\n",
    "    state_list = ['AK','AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','HI','IA','ID','IL','IN',\n",
    "        'KS','KY','LA','MA','MD','ME','MI','MN','MO','MS','MT','NC','ND','NE','NH','NJ','NM','NV',\n",
    "        'NY','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VA','VT','WA','WI','WV','WY']\n",
    "\n",
    "    df_raw = load_parquet_files(\"../data/raw\")\n",
    "    df_clean = clean_and_filter_columns(df_raw, cols, delay_cols)\n",
    "    df_filtered = filter_valid_states(df_clean, state_list)\n",
    "    df_filtered = df_filtered.drop(columns=['originstate', 'deststate'])\n",
    "    df_filtered = extract_hour_from_hhmm(df_filtered, 'crsdeptime', 'dep_hour')\n",
    "    df_filtered = extract_hour_from_hhmm(df_filtered, 'crsarrtime', 'arr_hour')\n",
    "    df_filtered = df_filtered.drop(columns=['crsdeptime', 'crsarrtime'])\n",
    "    df_filtered = add_holiday_features(df_filtered)\n",
    "    df_filtered = df_filtered.drop(columns=['year', 'flight_date'])\n",
    "    df_filtered['if_delay'] = np.where(df_filtered['arrdelayminutes'] <= 15, '0', '1').astype(int)\n",
    "    df_filtered['if_cancelled'] = np.where(df_filtered['cancelled'] == 0, '0', '1').astype(int)\n",
    "    df_filtered['if_diverted'] = np.where(df_filtered['diverted'] == 0, '0', '1').astype(int)\n",
    "    df_filtered = df_filtered.drop(columns=['cancelled', 'diverted'])\n",
    "    df_filtered['nonweatherdelay'] = df_filtered['arrdelayminutes'] - df_filtered['weatherdelay']\n",
    "    top_airports = get_top_airports(df_filtered)\n",
    "    df_final = filter_by_top_airports(df_filtered, top_airports)\n",
    "    \n",
    "    print(\"✅ FINAL DATASET CREATED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available parquet files (12):  ['flight_data_2024_9.parquet', 'flight_data_2025_3.parquet', 'flight_data_2024_8.parquet', 'flight_data_2025_2.parquet', 'flight_data_2025_1.parquet', 'flight_data_2025_4.parquet', 'flight_data_2024_7.parquet', 'flight_data_2024_12.parquet', 'flight_data_2025_5.parquet', 'flight_data_2024_11.parquet', 'flight_data_2025_6.parquet', 'flight_data_2024_10.parquet']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import os\n",
    "\n",
    "#############################################################################################################\n",
    "### FUNCTIONS\n",
    "#############################################################################################################\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "### Load parquet files (should have 12 months worth of data)\n",
    "### ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def load_parquet_files(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "    print(\"Available parquet files (\" + str(len(files)) + \"): \", files)\n",
    "    df = pd.concat([pd.read_parquet(os.path.join(directory, f)) for f in files], ignore_index=True)\n",
    "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "    return df\n",
    "\n",
    "df = load_parquet_files(\"../data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>flightdate</th>\n",
       "      <th>reporting_airline</th>\n",
       "      <th>dot_id_reporting_airline</th>\n",
       "      <th>iata_code_reporting_airline</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>...</th>\n",
       "      <th>div4tailnum</th>\n",
       "      <th>div5airport</th>\n",
       "      <th>div5airportid</th>\n",
       "      <th>div5airportseqid</th>\n",
       "      <th>div5wheelson</th>\n",
       "      <th>div5totalgtime</th>\n",
       "      <th>div5longestgtime</th>\n",
       "      <th>div5wheelsoff</th>\n",
       "      <th>div5tailnum</th>\n",
       "      <th>unnamed:_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>19393</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7889A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>19393</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7857B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>19393</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8567Z</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>19393</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8897K</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  quarter  month  dayofmonth  dayofweek  flightdate reporting_airline  \\\n",
       "1  2024        3      9           1          7  2024-09-01                WN   \n",
       "2  2024        3      9           1          7  2024-09-01                WN   \n",
       "3  2024        3      9           1          7  2024-09-01                WN   \n",
       "4  2024        3      9           1          7  2024-09-01                WN   \n",
       "\n",
       "   dot_id_reporting_airline iata_code_reporting_airline tail_number  ...  \\\n",
       "1                     19393                          WN      N7889A  ...   \n",
       "2                     19393                          WN      N7857B  ...   \n",
       "3                     19393                          WN      N8567Z  ...   \n",
       "4                     19393                          WN      N8897K  ...   \n",
       "\n",
       "   div4tailnum  div5airport  div5airportid  div5airportseqid div5wheelson  \\\n",
       "1          NaN          NaN            NaN               NaN          NaN   \n",
       "2          NaN          NaN            NaN               NaN          NaN   \n",
       "3          NaN          NaN            NaN               NaN          NaN   \n",
       "4          NaN          NaN            NaN               NaN          NaN   \n",
       "\n",
       "  div5totalgtime div5longestgtime  div5wheelsoff div5tailnum  unnamed:_109  \n",
       "1            NaN              NaN            NaN         NaN           NaN  \n",
       "2            NaN              NaN            NaN         NaN           NaN  \n",
       "3            NaN              NaN            NaN         NaN           NaN  \n",
       "4            NaN              NaN            NaN         NaN           NaN  \n",
       "\n",
       "[4 rows x 110 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "### SUMMARY STATISTICS DATASET\n",
    "#############################################################################################################\n",
    "\n",
    "summary_cols = ['holiday_code', 'dayofweek']\n",
    "\n",
    "df_summary = df_final.copy().groupby(summary_cols).agg(\n",
    "    total_flights = ('if_delay', 'count'),\n",
    "    delayed_flights = ('if_delay', 'sum'),\n",
    "    cancelled_flights = ('if_cancelled', 'sum'),\n",
    "    diverted_flights = ('if_diverted', 'sum'),\n",
    "    total_delay_minutes = ('arrdelayminutes', 'sum'),\n",
    "    delay_minutes_75th = ('arrdelayminutes', lambda x: int(x.quantile(0.75))),\n",
    "    delay_minutes_90th = ('arrdelayminutes', lambda x: int(x.quantile(0.90))),\n",
    "    delay_minutes_95th = ('arrdelayminutes', lambda x: int(x.quantile(0.95))),\n",
    "    delay_minutes_99th = ('arrdelayminutes', lambda x: int(x.quantile(0.99)))\n",
    ").reset_index()\n",
    "\n",
    "# df_summary.to_parquet('../data/processed/summary_dataset.parquet')\n",
    "\n",
    "df_summary.sort_values(by=\"delay_minutes_95th\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "### MACHINE LEARNING DATASET\n",
    "#############################################################################################################\n",
    "\n",
    "ml_cols = ['month', 'dayofweek', 'origin', 'dest', 'reporting_airline', 'dep_hour', 'holiday_code', 'holiday_proximity_bucket', 'arrdelayminutes']\n",
    "\n",
    "df_ml = df_final[ml_cols].copy()\n",
    "\n",
    "df_ml.to_parquet('../data/processed/ml_dataset.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_sandbox_cols = ['if_near_holiday']\n",
    "\n",
    "df_summary_sandbox = df_final.copy().groupby(summary_sandbox_cols).agg(\n",
    "    total_flights = ('if_delay', 'count'),\n",
    "    delayed_flights = ('if_delay', 'sum'),\n",
    "    cancelled_flights = ('if_cancelled', 'sum'),\n",
    "    diverted_flights = ('if_diverted', 'sum'),\n",
    "    total_delay_minutes = ('arrdelayminutes', 'sum'),\n",
    "    delay_minutes_90th = ('arrdelayminutes', lambda x: int(x.quantile(0.90))),\n",
    "    delay_minutes_95th = ('arrdelayminutes', lambda x: int(x.quantile(0.95))),\n",
    "    delay_minutes_99th = ('arrdelayminutes', lambda x: int(x.quantile(0.99))),\n",
    ").reset_index()\n",
    "\n",
    "df_summary_sandbox['avg_delay'] = df_summary_sandbox['total_delay_minutes'] / df_summary_sandbox['delayed_flights']\n",
    "df_summary_sandbox['delay_percent'] = (100 * df_summary_sandbox['delayed_flights'] / df_summary_sandbox['total_flights']).round(1)\n",
    "df_summary_sandbox['delay_percent_str'] = (100 * df_summary_sandbox['delayed_flights'] / df_summary_sandbox['total_flights']).round(1).astype(str) + '%'\n",
    "df_summary_sandbox['cancelled_percent'] = (100 * df_summary_sandbox['cancelled_flights'] / df_summary_sandbox['total_flights']).round(1).astype(str) + '%'\n",
    "df_summary_sandbox['diverted_percent'] = (100 * df_summary_sandbox['diverted_flights'] / df_summary_sandbox['total_flights']).round(1).astype(str) + '%'\n",
    "\n",
    "df_summary_sandbox.sort_values(by='delay_percent').tail(20)\n",
    "\n",
    "#df_summary_sandbox[df_summary_sandbox['origin'] == \"STS\"].sort_values(by='delay_percent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Code                                        Description  \\\n",
      "1467  DCA  Washington, DC: Ronald Reagan Washington National   \n",
      "\n",
      "                                    airport_ui  \n",
      "1467   Ronald Reagan Washington National (DCA)  \n"
     ]
    }
   ],
   "source": [
    "#MAPS_DATA_DIR = os.path.join(os.path.dirname(__file__), '..', 'data', 'maps')\n",
    "\n",
    "df = pd.read_csv('../data/maps/L_AIRPORT.csv')\n",
    "\n",
    "df['airport_ui'] = df['Description'].str.split(':').str[-1] + ' (' + df['Code'] + ')'\n",
    "\n",
    "print(df[df['Code'] == 'DCA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m../data/maps/L_UNIQUE_CARRIERS.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m df\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/maps/L_UNIQUE_CARRIERS.csv')\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b42aa77ed5f5b42884b87ca53fed36318530525cc8445095b22cbadc9646f115"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
